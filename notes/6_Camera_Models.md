---
title: "6 相机模型"
author: "ja50n"
date: "2022-09-06"
---

针孔相机是一个很容易模拟的模型，但它的问题是没有焦距，所有距离的物体都是清晰成像，显得很不真实。同时，光线和 radiance 的分布在经过透镜前后都会有很大变化，这些对于真实感渲染都非常重要。

光晕、枕形失真、桶状畸变等等效果，虽然是在镜片制作过程中尽力消除的特性，但还是会表现在成像上。

相机模型由一个抽象基类描述，`Camera` 类的主要方法是

- `Camera::GenerateRay()`，为底片上的一个采样生成世界坐标下的光线，行为因不同的成像模型而异
- `Camera::GenerateRayDifferential()`，除了生成光线，还会计算采样的面积以进行抗锯齿。

<!-- TODO add the chapter 16 reference -->

[16 章]()会介绍用于双向光传播的额外方法。

本章的内容是从简单针孔相机逐渐推广到带透镜组的相机模型。

# 1 相机模型

相机的构造函数需要一个 `AnimatedTransform` 将相机放入世界坐标系中，同时支持相机移动。由于需要实现动作模糊，相机也有一对时间参数控制快门的开合间隔。此外，相机还需要接收存放成像结果的 `Film` 和自身所在的 `Medium`。这些也是 `Camera` 基类的所有成员变量。

被定义为纯虚函数的 `Camera::GenerateRay()` 根据传入的 `CameraSample` 生成一条光线，注意*光线的方向向量需要单位化*。而 `CameraSample` 结构体存储生成一条光线需要的所有信息：光线需要经过的透镜上的点、底片上的点和产生时间（归一化的值，取值范围是 $[0, 1)$，需要根据相机自身的快门时间区间做 LERP）。这个函数的返回值代表通过此光线到达底片的 radiance 对最终成像的贡献程度。

`GenerateRayDifferential()` 和 `GenerateRay()` 一样会生成一条光线，但还会生成分别沿着底片轴向各一个像素的两条辅助光线。这部分光线微分量表示一条光线的采样在底片上的面积，可以用于纹理采样的 mipmap 和抗锯齿。函数实现上，只是从传入的 `CameraSample` 调用三次 `GenerateRay` 而已。如果一条辅助光线的 radiance 贡献是 0，就认为主光线的贡献也是 0。

## 1.1 相机坐标空间

（按照书的章节顺序）至今遇到的三个坐标空间：

- 物体空间：几何图元定义在的坐标空间，集合体的其他坐标都是相对于这个空间的。
- 世界空间：所有几何图元共同位于的空间，也是所有其他空间附属的空间，几何图元拥有一个变换矩阵，用于将自身的坐标变换到世界空间中。
- 相机空间：表示形式类似 OpenGL，但是左手系下，视线方向为 Z 轴正方向。基本是用于做视锥裁剪。

# 2 投影相机模型

三维 CG 的一个基本问题是如何将三维场景投射到二维平面上以供显示。许多经典的方法都可以被描述为一个四阶的投影变换矩阵。因此，这节我们实现一个投影矩阵相机类（projection matrix camera class）`ProjectiveCamera`，然后基于它实现两种投影：正交投影和透视投影。

对于投影相机，明确三个坐标系有助于后续的讨论：

- 屏幕空间：屏幕空间定义在底片上，但仍然是一个三维空间，相机将相机空间的物体投影到底片平面上，而在*屏幕窗口*内的部分才是会出现在结果图像上的。深度值 z 的取值范围为 $[0, 1]$，对应近平面和远平面之间的位置。这个概念应该对应视锥。
- 标准设备坐标（Normalized Device Coordinate）空间：一个 $[0, 1]^3$ 空间，由屏幕空间线性变换得到，XY 平面的原点在左上角，而 z 坐标的含义与屏幕空间的相同。
- 光栅空间：与 NDC 空间相同，但是 x 和 y 坐标的取值可以到各自分辨率的最大值，而不是归一化的值。

世界空间内的物体被变换到相机空间，其中在屏幕空间内的物体被投影到近平面的底片上，底片在光栅空间内位于从 $(0, 0, 0)$ 到 $(resolution.x, resolution.y, 0)$ 的平面范围上，而 NDC 空间将光栅空间标准化为 $[0, 1]^3$ 空间。这些空间之间的转换都可以用四阶方阵表示。

除了 `Camera` 基类构造函数需要的参数外，`ProjectiveCamera` 还需要投影变换矩阵（相机空间到屏幕空间）、二维图像在屏幕空间（即屏幕窗口）的尺寸，以及与景深相关的几个参数（用于实现焦散模糊）。传入的变换矩阵是相机空间到屏幕空间，屏幕空间到光栅空间的矩阵可以从二维屏幕窗口的尺寸直接计算，其他矩阵都可以计算出来。比较重要的变换是屏幕空间到光栅空间的投影，其计算顺序需要注意，且 Y 轴的方向发生了翻转。

<!-- TODO 翻转改变了手性，这个有副作用吗？ -->

## 2.1 正交投影相机

正交投影相机的成像基于正交投影变换。正交投影的视区（view volume）是一个相机空间的轴对齐盒，盒内所有场景都被平行投影到盒子与近平面重合的面上。这种成像方法没有近大远小（foreshortening）效果，但是实际物体的平行线仍然是平行的，且物体之间的相对距离也被保留下来。成像结果看起来非常浅。

正交投影将近平面变换到 z = 0，远平面到 z = 1，因此其调用投影相机基类的构造函数时，将相机空间到屏幕空间的变换设定为一个正交变换：沿 Z 轴向后平移使近平面与 XY 平面重合，再缩放 z 坐标使近平面和远平面之间的坐标都在 $[0, 1]$。

> 但是实际上，传给投影相机基类的相机空间到屏幕空间的变换是一个单位矩阵。近平面的 z 坐标不影响正交投影的正确成像，pbrt 作为 ray tracer 也并不关心远平面的位置（没有裁剪作用），但是语义上有点问题。

对于正交投影，底片每个位置的光线微分也是一样的，可以预计算。

生成光线的逻辑就是，采样器传来一个在光栅空间内的采样位置，变换为相机空间后得到光线起点（近平面上），然后根据坐标系和正交投影的特性，光线的方向就是 $(0, 0, 1)$，光线的时间根据采样信息的归一化时间在相机快门时间区间做 LERP，将光线由相机空间转换到世界空间再返回即可。

如果启用了景深效果（透镜半径大于 0），就需要计算光线出发经过透镜折射后的出射点，以及其他信息（后面会提到）。

生成光线微分的逻辑是类似的。利用预计算的微分量算出两条辅助光线的源点，方向（在没有景深的情况下）与主光线相同。

## 2.2 透视投影相机

pbrt 的屏幕空间太奇怪了，投影变换的推导也很奇怪。

这部分只着重讲一下投影变换矩阵是怎么推导的。

pbrt 的投影变换不是将相机空间内远近平面之间的坐标都变换到近平面上，也就是说不是从 frustum 到 cuboid 的操作。它的操作一直是将相机空间变换到屏幕空间，而屏幕空间内短边是 $[-1, 1]$ 的，长边按照 raster 空间的分辨率比例确定长度，深度映射到 $[0, 1]$，因此有不一样的变换计算。

首先明确一点，齐次坐标下引入的第四分量可以使三维空间坐标的表达式在分母上出现前三个坐标的线性组合。

利用这一点，我们先确定 x 和 y 坐标的变换，要将这两个分量映射到短边在 $[-1, 1]$ 的空间，假设高确实是短边，而传入的 fov 是竖直方向的，我们可以直接将 x 和 y 坐标除以 z 坐标对应深度上 y（高度）的最大值，即 $z\tan(\frac{fov}{2})$，就能完成映射，即确定投影矩阵的前两行。注意这里在分母引入了 z 坐标，第四分量需要设为 $z$，也就是说投影矩阵的第四行第三列是 $1$。

然后我们确定 z 的映射，即确定第三行。由于深度的映射与其他两个坐标无关，第三行前两个元素为 $0$。后两个元素通过待定系数法就可以求出来。

pbrt-book 上的推导省略了好多东西，而且顺序看不大懂。

<!-- TODO 屏幕空间的近平面保持了原始分辨率的比例，只有短边的取值在 $[-1, 1]$。这块的作用和要注意的地方后面要补上。 -->

光线微分和正交投影一样，也是可以预计算的，因为（照目前理解）都是平的底片上的一个偏移。

<!-- TODO 光线微分的原理到底是什么 -->

<!-- TODO 6.2.2 及之后跳过 -->

